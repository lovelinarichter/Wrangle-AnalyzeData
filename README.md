# Wrangle and Analyze Data

## Description
The goal of this project is to wrangle WeRateDogs Twitter data to create analysis and visualizations. 

The tasks in this project are as follows:

1. Data wrangling, which consists of:
- Gathering data
- Assessing data
- Cleaning data
2. Storing, analyzing, and visualizing the wrangled data
3. Reporting on:
 - Data wrangling efforts 
 - Data analyses and visualizations

## Installation
Install Anaconda libraries of Python. The code should run with no issues using Python versions 3.*.

For this project, access to Tweepy is required to query Twitter's API for additional data beyond the data included in the WeRateDogs Twitter archive. To get access to Tweepy, sign-up/login to Twitter, then follow the directions on Twitter’s Developer Portal, in the “How to Apply” section.

## File Descriptions
The files included in this repo are:
1. wrangle_act.ipynb - code in Jupyter notebook
2. wrangle_act.html - HTML copy of code
3. Wrangle_Report.PDF - steps taken to cleanup and analyze the WeRateDogs Twitter Archive Data.
4. Act_Report.PDF - analysis report

Three sources of data:<br>
1.Twitter Archive CSV format<br>
2. Prediction Data TSV format<br>
3. Twitter API<br>

## Licensing
Must give credit to Udacity and Twitter for the data.
